{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Package Installation and Environment Initialization"
      ],
      "metadata": {
        "id": "FCCG8j2GEiav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric --quiet\n",
        "!pip install torch --quiet\n",
        "!pip install pandas --quiet\n",
        "!pip install rdkit --quiet\n",
        "!pip install numpy --quiet\n",
        "!pip install matplotlib --quiet\n",
        "!pip install seaborn --quiet"
      ],
      "metadata": {
        "id": "C9qYkqq9EsPo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Dataset\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, Draw\n",
        "from rdkit.Chem import rdPartialCharges\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.data import Batch\n",
        "from torch_geometric.loader import DenseDataLoader\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "qERLGywqEyjU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "VHyGJYh0pRQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa0599c5-b643-4dea-cc6a-2b617074c0df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "metadata": {
        "id": "UvyWI7qPFJqH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading & Initial Exploration"
      ],
      "metadata": {
        "id": "blUfNzK1FNnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y4AAIytAFSYQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7ea7c4d-69ed-4c59-b71d-1d3a5809e2eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the train dataset\n",
        "file_path = '/content/drive/My Drive/GNN Project Materials/train_dataset.csv'\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "train_df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows\n",
        "print(train_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDDVqYz2FRfi",
        "outputId": "2cf398d7-6e67-489e-e716-8800c1ea53ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                            buildingblock1_smiles buildingblock2_smiles  \\\n",
            "0   0  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
            "1   1  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
            "2   2  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
            "3   3  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
            "4   4  C#CC[C@@H](CC(=O)O)NC(=O)OCC1c2ccccc2-c2ccccc21  C#CCOc1ccc(CN)cc1.Cl   \n",
            "\n",
            "     buildingblock3_smiles  \\\n",
            "0  Br.Br.NCC1CCCN1c1cccnn1   \n",
            "1  Br.Br.NCC1CCCN1c1cccnn1   \n",
            "2  Br.Br.NCC1CCCN1c1cccnn1   \n",
            "3        Br.NCc1cccc(Br)n1   \n",
            "4        Br.NCc1cccc(Br)n1   \n",
            "\n",
            "                                                          molecule_smiles  \\\n",
            "0  C#CCOc1ccc(CNc2nc(NCC3CCCN3c3cccnn3)nc(N[C@@H](CC#C)CC(=O)N[Dy])n2)cc1   \n",
            "1  C#CCOc1ccc(CNc2nc(NCC3CCCN3c3cccnn3)nc(N[C@@H](CC#C)CC(=O)N[Dy])n2)cc1   \n",
            "2  C#CCOc1ccc(CNc2nc(NCC3CCCN3c3cccnn3)nc(N[C@@H](CC#C)CC(=O)N[Dy])n2)cc1   \n",
            "3     C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)N[Dy])n2)cc1   \n",
            "4     C#CCOc1ccc(CNc2nc(NCc3cccc(Br)n3)nc(N[C@@H](CC#C)CC(=O)N[Dy])n2)cc1   \n",
            "\n",
            "  protein_name  binds      mol_wt    logP  rotamers  \n",
            "0         BRD4      0  703.192320  2.1410     16384  \n",
            "1          HSA      0  703.192320  2.1410     16384  \n",
            "2          sEH      0  703.192320  2.1410     16384  \n",
            "3         BRD4      0  711.049734  3.0397      8192  \n",
            "4          HSA      0  711.049734  3.0397      8192  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9w4-3MII07q",
        "outputId": "63833e8c-3c4d-4360-dd14-16e851088211"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                       5246830\n",
            "buildingblock1_smiles    5246830\n",
            "buildingblock2_smiles    5246830\n",
            "buildingblock3_smiles    5246830\n",
            "molecule_smiles          5246830\n",
            "protein_name             5246830\n",
            "binds                    5246830\n",
            "mol_wt                   5246830\n",
            "logP                     5246830\n",
            "rotamers                 5246830\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop building block SMILES columns\n",
        "train_df.drop(columns=['buildingblock1_smiles', 'buildingblock2_smiles', 'buildingblock3_smiles'], inplace=True)"
      ],
      "metadata": {
        "id": "hSVl5vdrJPWa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Addressing Target Imbalance"
      ],
      "metadata": {
        "id": "26BnHYlJjD6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check unique values in the 'binds' column\n",
        "print(train_df['binds'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2xXI_LaOCB6",
        "outputId": "1c9ea872-0b92-47ef-a279-4168d35a7f2c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binds\n",
            "0    5236321\n",
            "1      10509\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Separate the data into two parts: one for binds = 0 and one for binds = 1\n",
        "binds_0_df = train_df[train_df['binds'] == 0]\n",
        "binds_1_df = train_df[train_df['binds'] == 1]\n",
        "\n",
        "# Step 2: Downsample binds = 0 to match the number of binds = 1\n",
        "binds_0_downsampled_df = binds_0_df.sample(n=len(binds_1_df), random_state=42)\n",
        "\n",
        "# Step 3: Combine the downsampled binds = 0 data with binds = 1 data\n",
        "balanced_df = pd.concat([binds_0_downsampled_df, binds_1_df])\n",
        "\n",
        "# Step 4: Shuffle the final dataset to mix the rows\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Step 5: Verify the shape and class distribution\n",
        "print(f\"Balanced dataset shape: {balanced_df.shape}\")\n",
        "print(f\"Class distribution in balanced dataset: {balanced_df['binds'].value_counts()}\")\n",
        "\n",
        "# Step 6: Show the first few rows of the balanced dataset\n",
        "balanced_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "F2nQd7PLUBAj",
        "outputId": "98fb5674-4cc0-4b87-9d35-90067d8ef803"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced dataset shape: (21018, 7)\n",
            "Class distribution in balanced dataset: binds\n",
            "0    10509\n",
            "1    10509\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  \\\n",
              "0  3566327   \n",
              "1  4617174   \n",
              "2  1425402   \n",
              "3   959535   \n",
              "4   617223   \n",
              "\n",
              "                                                               molecule_smiles  \\\n",
              "0         C#CC[C@H](CC(=O)N[Dy])Nc1nc(NCC2Cc3ccccc3NC2=O)nc(Nc2ccc(Br)nc2OC)n1   \n",
              "1          C#CC[C@H](Nc1nc(NCc2ccc(OC)c(OC)c2C)nc(Nc2ccc(O)cc2Cl)n1)C(=O)N[Dy]   \n",
              "2       C#CC[C@@H](Nc1nc(NCc2ccccc2-c2cnn(C)c2)nc(Nc2cccc(Br)c2C)n1)C(=O)N[Dy]   \n",
              "3  C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2ccc(C)cc2OC2CCOC2)nc(Nc2ccc3c(c2)CNC3=O)n1   \n",
              "4        C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCCNC(=O)c2ccno2)nc(Nc2nc3c(C)cccc3s2)n1   \n",
              "\n",
              "  protein_name  binds      mol_wt     logP  rotamers  \n",
              "0          sEH      0  742.055548  2.77860      2048  \n",
              "1         BRD4      1  674.094830  3.29622      2048  \n",
              "2         BRD4      0  722.065718  4.08302      1024  \n",
              "3         BRD4      1  719.176001  2.72122      4096  \n",
              "4         BRD4      0  683.096705  2.13762      4096  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-200cc2fd-7718-488a-b88d-e9d2e25d900a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>molecule_smiles</th>\n",
              "      <th>protein_name</th>\n",
              "      <th>binds</th>\n",
              "      <th>mol_wt</th>\n",
              "      <th>logP</th>\n",
              "      <th>rotamers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3566327</td>\n",
              "      <td>C#CC[C@H](CC(=O)N[Dy])Nc1nc(NCC2Cc3ccccc3NC2=O)nc(Nc2ccc(Br)nc2OC)n1</td>\n",
              "      <td>sEH</td>\n",
              "      <td>0</td>\n",
              "      <td>742.055548</td>\n",
              "      <td>2.77860</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4617174</td>\n",
              "      <td>C#CC[C@H](Nc1nc(NCc2ccc(OC)c(OC)c2C)nc(Nc2ccc(O)cc2Cl)n1)C(=O)N[Dy]</td>\n",
              "      <td>BRD4</td>\n",
              "      <td>1</td>\n",
              "      <td>674.094830</td>\n",
              "      <td>3.29622</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1425402</td>\n",
              "      <td>C#CC[C@@H](Nc1nc(NCc2ccccc2-c2cnn(C)c2)nc(Nc2cccc(Br)c2C)n1)C(=O)N[Dy]</td>\n",
              "      <td>BRD4</td>\n",
              "      <td>0</td>\n",
              "      <td>722.065718</td>\n",
              "      <td>4.08302</td>\n",
              "      <td>1024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>959535</td>\n",
              "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCc2ccc(C)cc2OC2CCOC2)nc(Nc2ccc3c(c2)CNC3=O)n1</td>\n",
              "      <td>BRD4</td>\n",
              "      <td>1</td>\n",
              "      <td>719.176001</td>\n",
              "      <td>2.72122</td>\n",
              "      <td>4096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>617223</td>\n",
              "      <td>C#CC[C@@H](CC(=O)N[Dy])Nc1nc(NCCNC(=O)c2ccno2)nc(Nc2nc3c(C)cccc3s2)n1</td>\n",
              "      <td>BRD4</td>\n",
              "      <td>0</td>\n",
              "      <td>683.096705</td>\n",
              "      <td>2.13762</td>\n",
              "      <td>4096</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-200cc2fd-7718-488a-b88d-e9d2e25d900a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-200cc2fd-7718-488a-b88d-e9d2e25d900a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-200cc2fd-7718-488a-b88d-e9d2e25d900a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-59d8f742-2e4d-4e0b-8bec-89a14a3843cd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-59d8f742-2e4d-4e0b-8bec-89a14a3843cd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-59d8f742-2e4d-4e0b-8bec-89a14a3843cd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_df",
              "summary": "{\n  \"name\": \"balanced_df\",\n  \"rows\": 21018,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1629978,\n        \"min\": 122,\n        \"max\": 5246298,\n        \"num_unique_values\": 21018,\n        \"samples\": [\n          1925437,\n          4116144,\n          1941818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"molecule_smiles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20254,\n        \"samples\": [\n          \"C#CC[C@@H](CC(=O)N[Dy])Nc1nc(Nc2cncc(OC)c2)nc(Nc2nnn[nH]2)n1\",\n          \"C#CC[C@H](CC(=O)N[Dy])Nc1nc(NCC[C@@H]2COC[C@H]2O)nc(NCc2cccc(C(F)(F)F)n2)n1\",\n          \"C#CC[C@H](CC(=O)N[Dy])Nc1nc(NCC2C=CCC2)nc(NC2CCC(=O)CC2)n1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"protein_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"sEH\",\n          \"BRD4\",\n          \"HSA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"binds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mol_wt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54.921384662843046,\n        \"min\": 508.112672744,\n        \"max\": 922.098696532,\n        \"num_unique_values\": 13062,\n        \"samples\": [\n          587.048882612,\n          734.148070184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3173996906390937,\n        \"min\": -2.777399999999996,\n        \"max\": 8.324920000000002,\n        \"num_unique_values\": 16987,\n        \"samples\": [\n          6.749920000000005,\n          3.052420000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rotamers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10996,\n        \"min\": 128,\n        \"max\": 524288,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          262144,\n          131072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the sampled dataset to Drive\n",
        "sampled_file_path = '/content/drive/My Drive/GNN Project Materials/sampled_train_dataset.csv'\n",
        "balanced_df.to_csv(sampled_file_path, index=False)\n",
        "\n",
        "# Confirm file has been saved\n",
        "print(f\"Sampled dataset saved to: {sampled_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVmIazpnKhk7",
        "outputId": "a32618ca-74da-40dc-ee09-6c37c1a82f73"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled dataset saved to: /content/drive/My Drive/GNN Project Materials/sampled_train_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(balanced_df.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUk62Lz2MGAK",
        "outputId": "ecec484f-a6b6-4a84-acd3-fe5cb5891412"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id                 21018\n",
            "molecule_smiles    21018\n",
            "protein_name       21018\n",
            "binds              21018\n",
            "mol_wt             21018\n",
            "logP               21018\n",
            "rotamers           21018\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all SMILES are strings and not NaN\n",
        "balanced_df['molecule_smiles'] = balanced_df['molecule_smiles'].fillna(\"\").astype(str)\n",
        "\n",
        "# Check that every item is indeed a string\n",
        "print(balanced_df['molecule_smiles'].apply(type).unique())  # Should print <class 'str'>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUGyaF-F3iE6",
        "outputId": "059fb4dd-7fd3-4cc0-8b18-c07c420dc98b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<class 'str'>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieving Protein Sequences of `protein_name`\n",
        "\n"
      ],
      "metadata": {
        "id": "__69XTWiDsLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(balanced_df['protein_name'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUVOvXxfDH_4",
        "outputId": "851c6a87-b8d4-4a7c-a3c4-5bff55d83e46"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "protein_name\n",
            "HSA     7753\n",
            "BRD4    6746\n",
            "sEH     6519\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install biopython --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y09p62zrEZC9",
        "outputId": "d24ed9c8-3d75-475b-d269-031a41fde66f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m3.1/3.3 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import ExPASy\n",
        "from Bio import SeqIO\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Define the UniProt IDs for your proteins\n",
        "protein_ids = {\n",
        "    \"HSA\": \"P02768\",  # Human Serum Albumin\n",
        "    \"BRD4\": \"O60885\",  # Bromodomain-containing protein 4\n",
        "    \"sEH\": \"P34913\"   # Epoxide hydrolase 2\n",
        "}\n",
        "\n",
        "# Define the maximum sequence length (you need to determine this based on your data)\n",
        "MAX_PROTEIN_LEN = 619  # Or find the maximum length in your protein_sequences\n",
        "\n",
        "# Function to fetch protein sequence\n",
        "def fetch_sequence(uniprot_id):\n",
        "    try:\n",
        "        handle = ExPASy.get_sprot_raw(uniprot_id)  # Fetch the raw data from UniProt\n",
        "        record = SeqIO.read(handle, \"swiss\")  # Parse the data in Swiss-Prot format\n",
        "        handle.close()\n",
        "        return str(record.seq)  # Return the protein sequence as a string\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching sequence for {uniprot_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to pad or truncate protein sequences\n",
        "def pad_protein_sequence(sequence, max_len=MAX_PROTEIN_LEN, pad_char='X'):\n",
        "    \"\"\"Pads or truncates a protein sequence to a specific length.\"\"\"\n",
        "    if len(sequence) < max_len:\n",
        "        return sequence + pad_char * (max_len - len(sequence))\n",
        "    else:\n",
        "        return sequence[:max_len]\n",
        "\n",
        "# Fetch and print sequences\n",
        "protein_sequences = {}\n",
        "for protein, uniprot_id in protein_ids.items():\n",
        "    sequence = fetch_sequence(uniprot_id)\n",
        "    if sequence:\n",
        "        padded_sequence = pad_protein_sequence(sequence, max_len=MAX_PROTEIN_LEN)\n",
        "        protein_sequences[protein] = padded_sequence\n",
        "        print(f\"{protein} ({uniprot_id}): {sequence[:50]}...\")\n",
        "    else:\n",
        "        print(f\"Failed to fetch sequence for {protein} ({uniprot_id})\")\n",
        "\n",
        "# One-hot encode all padded sequences\n",
        "encoded_sequences = {}\n",
        "for protein, sequence in protein_sequences.items():\n",
        "    encoded_sequences[protein] = one_hot_encode_sequence(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF0JxU-bEZJw",
        "outputId": "f4d45fa6-85d7-411f-c646-2fafc82ffd22"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HSA (P02768): MKWVTFISLLFLFSSAYSRGVFRRDAHKSEVAHRFKDLGEENFKALVLIA...\n",
            "BRD4 (O60885): MSAESGPGTRLRNLPVMGDGLETSQMSTTQAQAQPQPANAASTNPPPPET...\n",
            "sEH (P34913): MTLRAAVFDLDGVLALPAVFGVLGRTEEALALPRGLLNDAFQKGGPEGAT...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the 20 standard amino acids\n",
        "amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"  # Alphabetical order\n",
        "aa_to_index = {aa: i for i, aa in enumerate(amino_acids)}  # Map each amino acid to an index\n",
        "\n",
        "print(\"Amino acid to index mapping:\")\n",
        "print(aa_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtWxw1_IExc1",
        "outputId": "63f83b27-d889-4006-cdae-0d4029e2509c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amino acid to index mapping:\n",
            "{'A': 0, 'C': 1, 'D': 2, 'E': 3, 'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10, 'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, 'V': 17, 'W': 18, 'Y': 19}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def one_hot_encode_sequence(sequence):\n",
        "    \"\"\"\n",
        "    Convert a protein sequence into a one-hot encoded matrix.\n",
        "    :param sequence: Protein sequence (string)\n",
        "    :return: One-hot encoded matrix (numpy array of shape [sequence_length, 20])\n",
        "    \"\"\"\n",
        "    encoding = np.zeros((len(sequence), len(amino_acids)), dtype=np.float32)  # Initialize matrix with float32 type\n",
        "    for i, aa in enumerate(sequence):\n",
        "        if aa in aa_to_index:  # Check if the amino acid is in the standard 20\n",
        "            encoding[i, aa_to_index[aa]] = 1  # Set the corresponding index to 1\n",
        "    return encoding\n",
        "\n",
        "# One-hot encode all sequences\n",
        "encoded_sequences = {}\n",
        "for protein, sequence in protein_sequences.items():\n",
        "    encoded_sequences[protein] = one_hot_encode_sequence(sequence)\n",
        "\n",
        "# Print shapes of encoded sequences\n",
        "for protein, encoded in encoded_sequences.items():\n",
        "    print(f\"{protein}: {encoded.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj7pkJBuE0hk",
        "outputId": "b2ba1d22-c3be-44ab-9952-9582dd6617f8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HSA: (619, 20)\n",
            "BRD4: (619, 20)\n",
            "sEH: (619, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting SMILES to Molecular Graphs"
      ],
      "metadata": {
        "id": "mSObwejlMuNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from collections import Counter\n",
        "\n",
        "def smiles_to_graph_with_protein(smiles, protein_name, binds, protein_sequences):\n",
        "    \"\"\"\n",
        "    Convert a SMILES string and protein sequence into a graph representation.\n",
        "\n",
        "    Args:\n",
        "        smiles (str): SMILES string of the ligand.\n",
        "        protein_name (str): Name of the protein (e.g., \"HSA\", \"BRD4\").\n",
        "        binds (int): Binary label indicating binding (0 or 1).\n",
        "        protein_sequences (dict): Dictionary mapping protein names to one-hot encoded sequences.\n",
        "\n",
        "    Returns:\n",
        "        Data: A PyTorch Geometric Data object.\n",
        "    \"\"\"\n",
        "    # Parse the SMILES string to create the molecule object\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        print(f\"Invalid SMILES string: {smiles}\")\n",
        "        return None\n",
        "\n",
        "    # Initialize lists for atom and bond features\n",
        "    atom_features = []\n",
        "    bond_index = []\n",
        "    bond_features = []\n",
        "\n",
        "    # Extract atom features\n",
        "    for atom in mol.GetAtoms():\n",
        "        features = [\n",
        "            atom.GetAtomicNum(),\n",
        "            atom.GetDegree(),\n",
        "            atom.GetTotalNumHs(),\n",
        "            atom.GetFormalCharge(),\n",
        "            int(atom.GetIsAromatic()),\n",
        "            int(atom.GetHybridization()),\n",
        "            atom.GetMass(),\n",
        "            atom.GetAtomicNum() / 100.0,  # Normalize atomic number\n",
        "            int(atom.IsInRing()),  # Whether atom is part of a ring\n",
        "            int(atom.GetChiralTag() != Chem.rdchem.ChiralType.CHI_UNSPECIFIED),  # Chiral center\n",
        "        ]\n",
        "        atom_features.append(features)\n",
        "\n",
        "    # Extract bond features\n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        bond_index.append((i, j))\n",
        "        bond_index.append((j, i))  # Bond is bidirectional\n",
        "        bond_features.append([bond.GetBondTypeAsDouble(), int(bond.GetIsAromatic()), bond.IsInRing()])\n",
        "        bond_features.append([bond.GetBondTypeAsDouble(), int(bond.GetIsAromatic()), bond.IsInRing()])\n",
        "\n",
        "    # Handle empty graphs\n",
        "    if len(atom_features) == 0 or len(bond_index) == 0:\n",
        "        print(f\"Skipping invalid SMILES string or empty graph: {smiles}\")\n",
        "        return None\n",
        "\n",
        "    # Convert features to tensors\n",
        "    atom_features = torch.tensor(atom_features, dtype=torch.float)\n",
        "    bond_index = torch.tensor(bond_index, dtype=torch.long).t().contiguous()\n",
        "    bond_features = torch.tensor(bond_features, dtype=torch.float)\n",
        "\n",
        "    # Scalar molecular features (Descriptors)\n",
        "    mol_wt = Descriptors.MolWt(mol)\n",
        "    logP = Descriptors.MolLogP(mol)\n",
        "    rotamers = Descriptors.NumRotatableBonds(mol)\n",
        "    tpsa = Descriptors.TPSA(mol)\n",
        "    qed = Descriptors.qed(mol)\n",
        "    # Additional molecular descriptors\n",
        "    heavy_atoms = Descriptors.HeavyAtomCount(mol)\n",
        "    h_acceptors = Descriptors.NumHAcceptors(mol)\n",
        "    h_donors = Descriptors.NumHDonors(mol)\n",
        "    # Adding more molecular descriptors\n",
        "    scalar_features = torch.tensor([mol_wt, logP, rotamers, tpsa, qed, heavy_atoms, h_acceptors, h_donors], dtype=torch.float)\n",
        "\n",
        "    # Get one-hot encoded protein sequence\n",
        "    if protein_name not in protein_sequences:\n",
        "        print(f\"Protein {protein_name} not found in protein_sequences.\")\n",
        "        return None\n",
        "    protein_encoded = protein_sequences[protein_name]  # One-hot encoded sequence\n",
        "    protein_encoded_tensor = torch.tensor(protein_encoded, dtype=torch.float)\n",
        "\n",
        "    # Additional protein features\n",
        "    protein_len = len(protein_encoded)  # Length of the protein sequence\n",
        "\n",
        "    # Modify this part to get amino acid counts correctly\n",
        "    aa_counts = Counter(protein_encoded.argmax(axis=1))  # Count amino acids based on argmax\n",
        "    aa_features = [aa_counts.get(aa, 0) / protein_len for aa in range(20)]  # Relative frequency of each amino acid\n",
        "\n",
        "    protein_length_tensor = torch.tensor([protein_len], dtype=torch.float)\n",
        "    aa_composition_tensor = torch.tensor(aa_features, dtype=torch.float)\n",
        "\n",
        "    # Create label tensor\n",
        "    if binds is None:\n",
        "        print(f\"No label for molecule: {smiles}\")\n",
        "        return None\n",
        "    label_tensor = torch.tensor([binds], dtype=torch.long)\n",
        "\n",
        "    # Return a Data object\n",
        "    return Data(\n",
        "        x=atom_features,  # Atom features\n",
        "        edge_index=bond_index,  # Edge indices\n",
        "        edge_attr=bond_features,  # Bond features\n",
        "        scalar_features=scalar_features.unsqueeze(0),  # Scalar molecular features\n",
        "        protein_feature=protein_encoded_tensor,  # One-hot encoded protein sequence\n",
        "        protein_len=protein_length_tensor,  # Protein sequence length\n",
        "        aa_composition=aa_composition_tensor,  # Amino acid composition features\n",
        "        y=label_tensor,  # Label tensor\n",
        "        protein_name=protein_name  # Add protein name here\n",
        "\n",
        "    )"
      ],
      "metadata": {
        "id": "XYnbEUFvMdm8"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# Split the dataset into train and test sets (80% train, 20% test)\n",
        "train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Function to process rows into graph data\n",
        "def create_graph_data(df, protein_sequences):\n",
        "    \"\"\"\n",
        "    Convert rows of the DataFrame into graph data.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing SMILES, protein names, and binding labels.\n",
        "        protein_sequences (dict): Dictionary mapping protein names to one-hot encoded sequences.\n",
        "\n",
        "    Returns:\n",
        "        list: List of PyTorch Geometric Data objects.\n",
        "    \"\"\"\n",
        "    graph_data_list = []\n",
        "    for i, row in df.iterrows():\n",
        "        graph_data = smiles_to_graph_with_protein(\n",
        "            row[\"molecule_smiles\"], row[\"protein_name\"], row[\"binds\"], protein_sequences\n",
        "        )\n",
        "        if graph_data is not None:\n",
        "            graph_data_list.append(graph_data)\n",
        "    return graph_data_list\n",
        "\n",
        "# Create graph data for train and test sets\n",
        "train_graph_data_list = create_graph_data(train_df, encoded_sequences)\n",
        "test_graph_data_list = create_graph_data(test_df, encoded_sequences)\n",
        "\n",
        "# Create DataLoaders for batching\n",
        "train_loader = DataLoader(train_graph_data_list, batch_size=32, shuffle=True, follow_batch=['protein_name'])\n",
        "test_loader = DataLoader(test_graph_data_list, batch_size=32, shuffle=False, follow_batch=['protein_name'])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejrFmHGNehS6",
        "outputId": "564a354a-2b78-4697-fd1b-37f5f1602fa4"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a GCN (Graph Convolutional Network)"
      ],
      "metadata": {
        "id": "PeGwtF0Qg_uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GNNModel(nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes, protein_feature_dim, dropout_rate):\n",
        "        super(GNNModel, self).__init__()\n",
        "\n",
        "        # Graph layers\n",
        "        self.conv1 = GCNConv(num_node_features, 64)\n",
        "        self.conv2 = GCNConv(64, 32)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(32)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        # Protein feature processing layers\n",
        "        self.protein_fc1 = nn.Linear(protein_feature_dim, 128)  # Adjust dimensions as needed\n",
        "        self.protein_fc2 = nn.Linear(128, 64)  # Adjust dimensions as needed\n",
        "        self.protein_batch_norm = nn.BatchNorm1d(64)\n",
        "        self.protein_dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        # Combined feature processing\n",
        "        self.fc1 = nn.Linear(32 + 64, 128)  # Combine graph and protein features\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.fc_dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch, protein_feature = data.x, data.edge_index, data.batch, data.protein_feature\n",
        "\n",
        "        # Graph convolution layers\n",
        "        x = torch.relu(self.conv1(x, edge_index))\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.conv2(x, edge_index))\n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = global_mean_pool(x, batch)  # Global pooling for graph features\n",
        "\n",
        "        # Protein feature processing\n",
        "        protein_x = torch.relu(self.protein_fc1(protein_feature))\n",
        "        protein_x = torch.relu(self.protein_fc2(protein_x))\n",
        "        protein_x = self.protein_batch_norm(protein_x)\n",
        "        protein_x = self.protein_dropout(protein_x)\n",
        "\n",
        "        # Get unique protein names from the batch\n",
        "        unique_protein_names = list(set(data.protein_name))\n",
        "\n",
        "        # Create a dictionary to map protein names to indices\n",
        "        protein_name_to_index = {name: i for i, name in enumerate(unique_protein_names)}\n",
        "\n",
        "        # Convert protein names to indices\n",
        "        protein_name_indices = [protein_name_to_index[name] for name in data.protein_name]\n",
        "\n",
        "        # Create a tensor of protein name indices\n",
        "        protein_name_tensor = torch.tensor(protein_name_indices, device=protein_feature.device)\n",
        "\n",
        "        # Get protein embeddings using indices\n",
        "        batch_protein_embeddings = protein_x[protein_name_tensor]\n",
        "\n",
        "        # Concatenate graph and protein features\n",
        "        x = torch.cat([x, batch_protein_embeddings], dim=1)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc_dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BWFErmNykMLY"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# 1. Define a function for training the model with early stopping\n",
        "def train_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=50, patience=10):\n",
        "    # Move model to the specified device (GPU/CPU)\n",
        "    model.to(device)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_without_improvement = 0\n",
        "    best_model_state = None  # To store the best model state\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)  # Move data to the correct device\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out, data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Calculate average training loss for the epoch\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}\", end=\"\")\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        with torch.no_grad():\n",
        "            for data in val_loader:\n",
        "                data = data.to(device)\n",
        "                out = model(data)\n",
        "                loss = criterion(out, data.y)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(out, dim=1)\n",
        "                val_preds.extend(predicted.cpu().numpy())\n",
        "                val_labels.extend(data.y.cpu().numpy())\n",
        "\n",
        "        # Calculate average validation loss and accuracy for the epoch\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "        print(f\", Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "            best_model_state = model.state_dict()  # Save the model with best validation loss\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(\"Early stopping triggered. Training stopped.\")\n",
        "            break\n",
        "\n",
        "    # Load the best model state\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "3S3YPRY7pHh-"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# 2. K-Fold Cross Validation\n",
        "def k_fold_cross_validation(k=5, num_epochs=50, patience=10, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')): # Use the device variable defined earlier\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    fold_accuracies = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_graph_data_list)):\n",
        "        print(f\"\\nFold {fold + 1}/{k}\")\n",
        "\n",
        "        # Create train and validation sets\n",
        "        train_data = [train_graph_data_list[i] for i in train_idx]\n",
        "        val_data = [train_graph_data_list[i] for i in val_idx]\n",
        "\n",
        "        # Create DataLoaders\n",
        "        train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "        val_loader = DataLoader(val_data, batch_size=16, shuffle=False)\n",
        "\n",
        "        # Get protein_feature_dim from your data\n",
        "        protein_feature_dim = train_graph_data_list[0].protein_feature.shape[1]  # Assuming protein_feature is a 2D tensor\n",
        "\n",
        "        # Initialize the model, criterion, and optimizer\n",
        "        model = GNNModel(num_node_features=10, num_classes=2, protein_feature_dim=protein_feature_dim, dropout_rate=0.2).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Train the model with early stopping\n",
        "        trained_model = train_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience)\n",
        "\n",
        "        # Evaluate the model on the validation set\n",
        "        trained_model.eval()\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in val_loader:\n",
        "                data = data.to(device)\n",
        "                if data.y is None:\n",
        "                    continue\n",
        "                out = trained_model(data)\n",
        "                _, predicted = torch.max(out, dim=1)\n",
        "                val_preds.extend(predicted.cpu().numpy())\n",
        "                val_labels.extend(data.y.cpu().numpy())\n",
        "\n",
        "        val_accuracy = accuracy_score(val_labels, val_preds)\n",
        "        print(f\"Fold {fold + 1} - Validation Accuracy: {val_accuracy:.4f}\")\n",
        "        fold_accuracies.append(val_accuracy)\n",
        "\n",
        "    avg_accuracy = sum(fold_accuracies) / k\n",
        "    print(f\"\\nAverage Validation Accuracy over {k} folds: {avg_accuracy:.4f}\")\n",
        "\n",
        "# Run K-Fold Cross-Validation, using the determined device\n",
        "k_fold_cross_validation(k=5, num_epochs=50, patience=5, device=device) # Pass the device variable"
      ],
      "metadata": {
        "id": "eIzQH8Wm3lOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "62ed0d72-f6cd-4652-ec14-37cda135e344"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 0.6589, Val Loss: 0.6366, Val Accuracy: 0.6310\n",
            "Epoch 2/50, Train Loss: 0.6388, Val Loss: 0.6307, Val Accuracy: 0.6384\n",
            "Epoch 3/50, Train Loss: 0.6322, Val Loss: 0.6203, Val Accuracy: 0.6203\n",
            "Epoch 4/50, Train Loss: 0.6115, Val Loss: 0.6472, Val Accuracy: 0.6328\n",
            "Epoch 5/50, Train Loss: 0.5936, Val Loss: 0.5513, Val Accuracy: 0.7035\n",
            "Epoch 6/50, Train Loss: 0.5810, Val Loss: 0.6033, Val Accuracy: 0.6747\n",
            "Epoch 7/50, Train Loss: 0.5802, Val Loss: 0.6441, Val Accuracy: 0.6340\n",
            "Epoch 8/50, Train Loss: 0.5701, Val Loss: 0.6450, Val Accuracy: 0.6705\n",
            "Epoch 9/50, Train Loss: 0.5620, Val Loss: 0.6866, Val Accuracy: 0.6221\n",
            "Epoch 10/50, Train Loss: 0.5590, Val Loss: 0.6328, Val Accuracy: 0.6830\n",
            "Early stopping triggered. Training stopped.\n",
            "Fold 1 - Validation Accuracy: 0.6830\n",
            "\n",
            "Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-e44f818637d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Run K-Fold Cross-Validation, using the determined device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mk_fold_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass the device variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-110-e44f818637d7>\u001b[0m in \u001b[0;36mk_fold_cross_validation\u001b[0;34m(k, num_epochs, patience, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Train the model with early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_with_early_stopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Evaluate the model on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-e20707219f09>\u001b[0m in \u001b[0;36mtrain_with_early_stopping\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mcY9JffG_gZd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}